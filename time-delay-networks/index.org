:PROPERTIES:
:ROAM_REFS: cite:LWH90
:ID:       635e1539-1669-4672-be26-6cb39d873e8c
:END:
#+title: A time-delay neural network architecture for isolated word recognition
#+OPTIONS: num:nil html-postamble:t html-style:nil toc:nil
#+DATE: [2024-08-21 Wed]
#+AUTHOR: Raghav B. Venkataramaiyer
# #+AUTHOR: B.V. Raghav, Subham Kumar, Vinay P. Namboodiri
#+EMAIL: bv.raghav@thapar.edu
# #+EMAIL: bvraghav@iitk.ac.in, subhamkr@iitk.ac.in, vinaypn@iitk.ac.in
#+LANGUAGE: en

#+HTML_HEAD: <meta name="keywords" content="Constrained links,Isolated word recognition,Multiresolution learning,Multispeaker speech recognition,Network architecture,Neural networks,Time delays">

#+HTML_HEAD: <meta name="description" content="Notes on Time delay neural networks">

#+HTML_HEAD: <meta name="viewport" content="width=device-width, initial-scale=1">
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="/css/dhiw.css" />
#+HTML_HEAD: <link rel="shortcut icon" type="image/png"
#+HTML_HEAD:   href="https://www.gravatar.com/avatar/034c3feded7a09f8a5c481a2bd35d676.png?s=16" />

#+HTML_HEAD: <style>
#+HTML_HEAD: .iframe-container {
#+HTML_HEAD:   overflow: hidden;
#+HTML_HEAD:   /* Calculated from the aspect ratio of the content (in case of 16:9 it is 9/16= 0.5625) */
#+HTML_HEAD:   padding-top: 56.25%;
#+HTML_HEAD:   position: relative;
#+HTML_HEAD:   margin-bottom: 1em;
#+HTML_HEAD: }
#+HTML_HEAD:  
#+HTML_HEAD: .iframe-container iframe {
#+HTML_HEAD:    border: 0;
#+HTML_HEAD:    height: 100%;
#+HTML_HEAD:    left: 0;
#+HTML_HEAD:    position: absolute;
#+HTML_HEAD:    top: 0;
#+HTML_HEAD:    width: 100%;
#+HTML_HEAD: }
#+HTML_HEAD: </style>

#+HTML_HEAD: <style type="text/css">
#+HTML_HEAD:  ol.alpha { list-style-type: lower-alpha; }
#+HTML_HEAD: </style>

#+PROPERTY: header-args+ :exports both :eval never-export
#+PROPERTY: header-args:python+ :results output replace verbatim

#+MACRO: cnc {{{sc(cnc)}}}


[[../][[Parent]​]]

- tags :: 
- keywords :: Constrained links, Isolated word
  recognition, Multiresolution learning, Multispeaker
  speech recognition, Network architecture, Neural
  networks, Time delays
- author :: Lang, K. J., Waibel, A. H., & Hinton, G. E.
- url :: [[https://www.sciencedirect.com/science/article/pii/089360809090044L][[Science Direct]​]] [[https://www.cs.toronto.edu/~hinton/absps/langTDNN.pdf][[PDF]​]]
- date :: 1990

#+toc: headlines 2

* Summary
:PROPERTIES:
:CUSTOM_ID: sec:summary
:END:

In the authors’ own words, in the context of
“difficult” word recognition, this literature documents
the success of,

#+begin_quote
a network that extracted features by repeatedly
convolving a set of narrow weight patterns with the
contents of a sliding window into the input.
#+end_quote

This is a widely referenced early work that lays
foundation for 1-D convolution based approaches in the
recent advances, like [[../jasper/][Jasper]] and its derivatives.

*See also*: [[#sec:dataset][Dataset]] to understand the problem better.

* Motivation
:PROPERTIES:
:CUSTOM_ID: sec:motivation
:END:

#+begin_quote
[…] the Viterbi-aligned speech fragments contained
enough alignment errors to motivate a shift-invariant
[model]
#+end_quote

Ref: [[#sec:viterbi-alignment][Viterbi Alignment]]

* Key Idea
:PROPERTIES:
:CUSTOM_ID: sec:key-idea
:END:

+ Neural networks are universal approximators;
+ Convolution controls model size; and
+ Pooling leads to positional invariance.

* Method
:PROPERTIES:
:CUSTOM_ID: sec:method
:END:

Let
#+attr_html: :style vertical-align:baseline
| <15>                                                        | <35>                                                                                                                                                                                                         |
| $\text{data}$                                               | be a set of $(y,\mathbf{x})$ pairs; $\mathbf{x}$ being the input vector, and $y\in\mathbb{Z}_{\geqslant0}$ being the labels.                                                                                 |
| $\mathbf{x}\in\mathbb{X}\subseteq\mathbb{R}^{C\times T}$    | be input vector; $C=16$ being number of channels; and $T$ being temporal resolution.                                                                                                                         |
| $\Phi(\;\cdot;\theta):\mathbb{X}\to\mathbb{R}^{K\times T'}$ | be 1-D convolutional neural network, with its output being a $T'$ long sequence of $K$ dimensional vector, representing word probabilities; $K$ being the vocabulary size and $\theta$ being network params. |
| $\boldsymbol{1}_{k}:\mathbb{Z}_{\geqslant0}\to\mathbb{R}^{k}$ | be whole number to one-hot vector converter                                                                                                                                                                  |
| $\parallel\,\cdot\,\parallel_{p,\mathrm{row}}$              | be an operator that computes $L_{p}$ norm for each row vector in the tensor, defined here for mathematical convenience.                                                                                      |
| $\mathbf{x}^{\otimes n}$                                    | be element-wise exponentiation operation, defined here for mathematical convenience.                                                                                                                         |
| $\Delta_{E}$                                                | be Euclidean distance between two vectors.                                                                                                                                                                   |
# | $\mathrm{avg}$                                              | be the average pooling operator.                                                                                                                                                                             |

\begin{align}
  \notag \theta_*
  &= \arg \min_{\theta} \underset {y,\mathbf{x}
    \sim\text{data}} {\mathbb{E}} \left[ \Delta(y,
    f(\mathbf{x};\theta)) \right] \\
  \notag f(\mathbf{x};\theta)
  &= \left\| \Phi(\mathbf{x};
    \theta) \right\|_{2,\mathrm{row}}^2 \\
  \notag \Delta(y, \widetilde{\mathbf{y}})
  &= \Delta_E \left(\boldsymbol{1}_K(y),
    \widetilde{\mathbf{y}} \right)
\end{align}

Update 2024-08-28[fn:1].

# \begin{align}
#   \notag \theta_*
#   &= \arg \min_{\theta} \underset {y,\mathbf{x}
#     \sim\text{data}} {\mathbb{E}} \left[ \Delta(y,
#     f(\mathbf{x};\theta)) \right] \\
#   \notag f(\mathbf{x};\theta)
#   &= \mathrm{avg} \circ \left\| \Phi(\mathbf{x};
#     \theta) \right\|_{2,\mathrm{row}}^2 \\
#   \notag \Delta(y, \widetilde{\mathbf{y}})
#   &= \Delta_E \left(\boldsymbol{1}_K(y),
#     \widetilde{\mathbf{y}} \right)
# \end{align}



# * Experiments
# :PROPERTIES:
# :CUSTOM_ID: sec:experiments
# :END:

* Dataset
:PROPERTIES:
:CUSTOM_ID: sec:dataset
:END:

400 samples

#+begin_quote
the four *words*, “bee,” “dee,” “ee,” and “vee” [B, D,
E, and V] were used; earlier IBM research had shown
that these four words were the most confusable members
of the E-set of the alphabet.
#+end_quote

# * Results
# :PROPERTIES:
# :CUSTOM_ID: sec:results
# :END:

* Appendix
:PROPERTIES:
:CUSTOM_ID: sec:appendix
:END:

** Feature Extraction
:PROPERTIES:
:CUSTOM_ID: sec:feature-extraction
:END:

Initial spectrogram feature was extracted from $150$ ms
waveform containing log energy values and bearing shape
$128\times48$; $128$ frequencies $\times48$ frames each
lasting $3$ ms.  In an experiment with input feature
size, it was observed, however that $16\times12$
input-based 2-layer hidden model exhibited the best
performance; $16$ frequency bands on linear scale
$\times12$ frames each lasting $12$ ms.

#+begin_quote
[…] the program converted our 150 ms waveform samples
into spectrograms containing 128 log energies ranging
up to 8 kHz, and 49 time frames of 3 ms each.  The
first frame of each spectrogram was then discarded so
that there would be 48 time steps (a highly
factorizable number), and the DC bias com- ponent of
each frame was set to zero.  Because each of the 48
time frames represented 3 ms, the final duration of the
spectrograms was 144 ms.
#+end_quote

** Viterbi Alignment
:PROPERTIES:
:CUSTOM_ID: sec:viterbi-alignment
:END:

In a prior art at IBM, a hidden Markov model (HMM) was
used to model the distribution of labels and spoken
word.  The Viterbi search listed the most likely
sequence of /labels/, corresponding to each frame of
utterance in a spoken word; where the word identity was
known.

#+begin_quote
These labels were used to extract a 150 ms salient
section of each utterance which included 100 ms before
the first frame that was labeled “E” (this region
should contain the consonant), plus 50 ms of the vowel.
#+end_quote

*HMM Model Details:*
#+begin_quote
[…] the words *B*, *D*, and *V* are modelled by a
concatenation of the state machines for _noise_,
_voiced consonant onset_, _{B,D,V}_, _E_, _E
trail-off_, and _noise_. The word *E* is modelled by a
concatenation of the state machines for _noise_, _E
onset_, _E_, _E trail-off_, and _noise_. The state
machines contain 3 main states with associated
transitions to model the _beginning_, _middle_, and
_end_ of each phone. The consonant and vowel machines
include *self-loops* to model steady-state portions of
the acoustic signal, and all of the machines include
_null transitions_ to model short durations.
#+end_quote

* Footnotes

[fn:1] /(Update 2024-08-28)/ Remove redundant average
pooling operator, (earlier $f(\mathbf{x};\theta) =
\mathrm{avg} \circ \left\| \Phi(\mathbf{x}; \theta)
\right\|_{2,\mathrm{row}}^2$).  The Frobenius norm at
row level, effectively defines the sum-squares pooling,
as in the TDNN paper.  Thus the vague average pooling
operator is eliminated.
